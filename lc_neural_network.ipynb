{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame.from_csv(\"X_data.csv\")\n",
    "y = pd.DataFrame.from_csv(\"y_data.csv\")\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train.iloc[:,1:], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_predict = pd.DataFrame(clf.predict_proba(X_test.iloc[:,1:]), index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel-4.2.2-py2.7.egg/ipykernel/__main__.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel-4.2.2-py2.7.egg/ipykernel/__main__.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A         B         C         D         E         F         G\n",
      "Bad   0.917442  0.841667  0.794434  0.738691  0.715175  0.656285  0.659189\n",
      "Good  0.935606  0.855116  0.808373  0.754008  0.723817  0.680087  0.641830\n"
     ]
    }
   ],
   "source": [
    "grades = [grade for grade in X_test.columns if grade[:6] == \"grade_\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for grade in grades:\n",
    "    good = y_test_predict[y_test == False][X_test[grade] == True][0].mean()\n",
    "    bad = y_test_predict[y_test == True][X_test[grade] == True][0].mean()\n",
    "    results[grade[-1]] = {'Good': good, \"Bad\": bad}\n",
    "\n",
    "print pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the probability of repayment for any given loan is high, out model will tend to predict that a loan will get repaid. However, the actual probability of repayment varies. From the above, the model shows potential as, even when broken out by grade, the model shows some predictive power. The only grade this did not hold for is grade G, which may be due to the small size.\n",
    "\n",
    "Since the model will tend to predict repayment for every loan, the score function is not very useful. Another way to score how well we're doing is to use the model to decide what loans to buy to maximize the loss-adjusted return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing number of hidden layers and neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
